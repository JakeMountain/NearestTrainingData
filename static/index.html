<html>
    <head>
        <meta charset="utf-8">
        <title>Training data nearest neighbors</title>
        <meta name="description" content="Find LLM training examples most similar to your prompt: uncover latent similarities.">
        <link rel="stylesheet" href="style.css">
    </head>
    <body>
        <div class="centered">
            <div class="content">
                <h1>
                    Enter a prompt to GPT:
                </h1>
                <input id="input" class="input" name="q" value="" placeholder="Type any topic or questionâ€¦" autocomplete="off">
                <button id="submit" class="primary button" type="submit">Submit</button>

            </div>
            <div id="loading" class="hidden">
              <div class="spinner"></div>
            </div>
            <div class="container hidden" id="results">
                <div class="text-column">
                  <h1>Response</h1>
                  <p id="response-text"></p>
                  <div class="response-embedding hidden" id="response-embedding"></div>
                </div>
                <div class="top_k">
                  <h1>Relevant training examples</h1>
                  <table id="neighbors">
                  </table>
                </div>
              </div>
              <div class="description-section">
                <p class="project-description">
                  This project uses the OpenWebText dataset, which consists of external links posted to Reddit. 
                  I embedded 150 million text pieces from that dataset and stored them. 
                  The output generated by GPT in response to a user prompt is compared against those sentences for semantic similarity. 
                  <br><br>
                  The comparison returns training examples that have a higher degree of similarity to the prompt and output. 
                  In theory, these examples exerted greater influence than other training data on the formation of the local latent space from which the output is drawn.
                  <br><br>
                  Made by Jake Mountain for ToftH School final project, June 2023. Special thank you to Max Braun for providing advice and for hopefully being cool with me reusing plenty of his flask code :)
                </p>
              </div>
        </div>
    </body>
    <script src="script.js"></script>
</html>